{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e13f15-e182-486d-b240-a511106c4533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\kumar\\appdata\\roaming\\python\\python313\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\kumar\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\kumar\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kumar\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kumar\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kumar\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20c0819-04b7-4385-9da0-b98a36038891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeac8301-08da-4c8f-bd76-fc3296bba5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama went as a prime minister of USA in the year of 2015 . PM MODI is the prime minister of INDIA.\n"
     ]
    }
   ],
   "source": [
    "input = \"Barack Obama went as a prime minister of USA in the year of 2015 . PM MODI is the prime minister of INDIA.\"\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a4c44dd-8acd-46fe-a387-b7abaf4a3d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOWERCSE =  barack obama went as a prime minister of usa in the year of 2015 . pm modi is the prime minister of india.\n",
      "REGULAR EXP1 =  barack obama went as a prime minister of usa in the year of 2025 . pm modi is the prime minister of india.\n",
      "REGULAR EXP2 =  **r*** o**** w*nt *s * pr*** **n*st*r o* us* *n t** y**r o* 2015 . p* *o** *s t** pr*** **n*st*r o* *n***.\n",
      "REGULAR EXP3 =  barack obama went as a prime minister of usa in the year of ---- . pm modi is the prime minister of india.\n"
     ]
    }
   ],
   "source": [
    "#(1)lowercase\n",
    "lowercase = input.lower()\n",
    "print(\"LOWERCSE = \", lowercase)\n",
    "\n",
    "#re\n",
    "#pip install re\n",
    "import re\n",
    "lowercase_re = re.sub('2015', '2025', lowercase)\n",
    "print(\"REGULAR EXP1 = \", lowercase_re)\n",
    "lowercase_re = re.sub('[a-m]', '*', lowercase)\n",
    "print(\"REGULAR EXP2 = \", lowercase_re)\n",
    "lowercase_re = re.sub('\\d', '-', lowercase)\n",
    "print(\"REGULAR EXP3 = \", lowercase_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e067636-c0fd-4054-8fbf-06c0893b25e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD TOKENS =  ['Barack', 'Obama', 'went', 'as', 'a', 'prime', 'minister', 'of', 'USA', 'in', 'the', 'year', 'of', '2015', '.', 'PM', 'MODI', 'is', 'the', 'prime', 'minister', 'of', 'INDIA', '.']\n",
      "24\n",
      "SENT TOKENS =  ['Barack Obama went as a prime minister of USA in the year of 2015 .', 'PM MODI is the prime minister of INDIA.']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#(2)Tokenization\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "word_tokens = word_tokenize(input)\n",
    "print(\"WORD TOKENS = \", word_tokens)\n",
    "print(len(word_tokens))\n",
    "sent_tokens = sent_tokenize(input)\n",
    "print(\"SENT TOKENS = \", sent_tokens)\n",
    "print(len(sent_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae53da8b-2045-4f67-be2d-bf4fc81b2236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama went prime minister USA year 2015 . PM MODI prime minister INDIA .\n"
     ]
    }
   ],
   "source": [
    "#(3)stopwords Removal\n",
    "from nltk.corpus import stopwords\n",
    "#print(stopwords.fileids())\n",
    "stopwords = set(stopwords.words('english'))\n",
    "#print(\"\\n\", stopwords)\n",
    "\n",
    "tokens_stopwords = []\n",
    "for token in word_tokens:\n",
    "    if token not in stopwords:\n",
    "        tokens_stopwords.append(token)\n",
    "print(' '.join(tokens_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c23538b-535d-4cb1-b304-e5e11c968c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['barack', 'obama', 'went', 'prime', 'minist', 'usa', 'year', '2015', '.', 'pm', 'modi', 'prime', 'minist', 'india', '.']\n"
     ]
    }
   ],
   "source": [
    "#Stemmer\n",
    "stemming = []\n",
    "from nltk import PorterStemmer\n",
    "for word in tokens_stopwords:\n",
    "    stemming.append(PorterStemmer().stem(word))\n",
    "print(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f718d0-f452-4f60-94de-340af56877f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barack', 'Obama', 'went', 'prime', 'minister', 'USA', 'year', '2015', '.', 'PM', 'MODI', 'prime', 'minister', 'INDIA', '.']\n"
     ]
    }
   ],
   "source": [
    "#Lemmatizer\n",
    "from nltk import WordNetLemmatizer\n",
    "lma = []\n",
    "for word in tokens_stopwords:\n",
    "    lma.append(WordNetLemmatizer().lemmatize(word))\n",
    "print(lma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe605117-7591-4057-b832-ff281c30c53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Barack', 'NNP'), ('Obama', 'NNP'), ('went', 'VBD'), ('as', 'IN'), ('a', 'DT'), ('prime', 'JJ'), ('minister', 'NN'), ('of', 'IN'), ('USA', 'NNP'), ('in', 'IN'), ('the', 'DT'), ('year', 'NN'), ('of', 'IN'), ('2015', 'CD'), ('.', '.'), ('PM', 'NNP'), ('MODI', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('prime', 'JJ'), ('minister', 'NN'), ('of', 'IN'), ('INDIA', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#POS Tags\n",
    "from nltk import pos_tag\n",
    "print(pos_tag(word_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17a03007-38dd-4deb-afd8-747ad0814cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53cc234c-f52f-4ad4-8ddc-f61a671f8e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8828268-17f5-408e-98a0-869a9dc78577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0f47601-f7cb-4191-bffc-1a7116d077fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02a14359-b5be-4a31-b7a8-61241d272674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n",
      "very so exceedingly heartily a as good great extremely remarkably\n",
      "sweet vast amazingly\n"
     ]
    }
   ],
   "source": [
    "text1.similar(\"monstrous\")\n",
    "text2.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72b0d2d-8667-4059-b7b8-04ef9a903f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
